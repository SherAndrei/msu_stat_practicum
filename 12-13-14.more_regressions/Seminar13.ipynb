{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 13. Гребневая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1\n",
    "\n",
    "В файле \"House_prices_corrected.csv\" представлены характеристики различных домов (стоимость, площадь, количество комнат, год постройки и тп, описание признаков можно найти по ссылке [__Ames Housing dataset__](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)).\n",
    "\n",
    "Изучить линейную зависимость стоимости домов (SalePrice) от всех остальных показателей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('House_prices_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = data.drop(['SalePrice'], 1)\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn` есть несколько классов, реализующих линейную регрессию:\n",
    "* [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) &mdash; \"классическая\" линейная регрессия с оптимизацией MSE\n",
    "* [`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) &mdash; линейная регрессия с оптимизацией MSE и $\\ell_2$-регуляризацией\n",
    "* [`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) &mdash; линейная регрессия с оптимизацией MSE и $\\ell_1$-регуляризацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lr = LinearRegression()\n",
    "lr = Ridge() #по умолчанию alpha=1.0, fit_intercept=True\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_hat_test = lr.predict(x_test)\n",
    "print('Test MSE %.3f' % mean_squared_error(y_test, y_hat_test))\n",
    "print('Test R2 %.3f' % r2_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat_train = lr.predict(x_train)\n",
    "print(\"Train MSE = %.3f\" % mean_squared_error(y_train, y_hat_train))\n",
    "print(\"Train R2 = %.3f\" % r2_score(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие признаки оказались самыми \"сильными\". Для этого визуализируем коэффициенты регрессии, соответствующие признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пример применения zip\n",
    "a = [1,2,3]\n",
    "b = [10, 20 ,30]\n",
    "c = [100, 200, 300]\n",
    "list(zip(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(a, b, c), reverse=True) #сортировка по 1ым элементам по убыванию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_weights(features, weights, scales):\n",
    "    fig, axs = plt.subplots(figsize=(14, 10), ncols=2) #ncols=2: два графика (два столбца)\n",
    "    sorted_weights = sorted(zip(weights, features, scales), reverse=True) #сортировка по весам по убыванию\n",
    "    weights = [x[0] for x in sorted_weights]\n",
    "    features = [x[1] for x in sorted_weights]\n",
    "    scales = [x[2] for x in sorted_weights]\n",
    "    sns.barplot(y=features, x=weights, ax=axs[0])\n",
    "    axs[0].set_xlabel(\"Weight\")\n",
    "    sns.barplot(y=features, x=scales, ax=axs[1])\n",
    "    axs[1].set_xlabel(\"Scale\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_weights(x_train.columns, lr.coef_, x_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем масштабировать наши признаки. Это сделает нашу регуляризацию более честной: теперь все признаки будут регуляризоваться в равной степени. \n",
    "\n",
    "Для этого воспользуемся трансформером [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Трансформеры в `sklearn` имеют методы `fit` и `transform` (а еще `fit_transform`). Метод `fit` принимает на вход обучающую выборку и считает по ней необходимые значения (среднее и стандартное отклонение каждого из признаков). `transform` применяет преобразование к переданной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test) #на test делаем только transform!\n",
    "\n",
    "lr = Ridge()\n",
    "lr.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_weights(x_train.columns, lr.coef_, x_train_scaled.std(axis=0)) #type(x_train_scaled) = numpy.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наряду с параметрами, которые модель оптимизирует на этапе обучения (коэффициенты регрессии), у модели есть и гиперпараметры. У нашей модели это `alpha` &mdash; коэффициент регуляризации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем пользоваться кросс-валидацией для подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем `alpha` по логарифмической сетке, чтобы узнать оптимальный порядок величины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def r2_squared(y_true, y_pred):\n",
    "    r2_coef = r2_score(y_true, y_pred)\n",
    "    return r2_coef\n",
    "\n",
    "r2_scorer = make_scorer(r2_squared, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-2, 3, 20)\n",
    "searcher = GridSearchCV(Ridge(), [{\"alpha\": alphas}], scoring=r2_scorer, cv=10) #scoring=\"r2\"\n",
    "searcher.fit(x_train_scaled, y_train)\n",
    "\n",
    "best_alpha = searcher.best_params_[\"alpha\"]\n",
    "print(\"Best alpha = %.4f\" % best_alpha)\n",
    "\n",
    "plt.plot(alphas, searcher.cv_results_[\"mean_test_score\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"CV score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge(best_alpha) \n",
    "lr.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_hat_test = lr.predict(x_test_scaled)\n",
    "print('Test MSE %.3f' % mean_squared_error(y_test, y_hat_test))\n",
    "print('Test R2 %.3f' % r2_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge() \n",
    "lr.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_hat_test = lr.predict(x_test_scaled)\n",
    "print('Test MSE %.3f' % mean_squared_error(y_test, y_hat_test))\n",
    "print('Test R2 %.3f' % r2_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_ #обратим внимание на то, что константа в регрессии не регуляризуется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
